# LLM Search Analysis - Project Plan

## Project Overview

Build a unified application to monitor and analyze how LLM models from multiple providers (OpenAI, Google, Anthropic, etc.) use web search and tool-calling capabilities. The app will allow interactive prompting and batch analysis to understand:
- What search queries models generate across different providers
- Which sources they fetch vs. which they cite
- How reasoning traces influence search behavior
- Search patterns and model decision-making
- Comparative analysis across different AI platforms and models

## Goals

1. **Multi-Provider Support**: Unified interface for OpenAI, Google (Gemini), Anthropic (Claude), and future providers
2. **Interactive Mode**: Send individual prompts and see detailed breakdowns of search behavior
3. **Batch Analysis**: Programmatically send multiple prompts for large-scale pattern analysis
4. **Cross-Provider Comparison**: Compare search behavior across different AI platforms and models
5. **Search Insights**: Understand search query patterns, source selection, and citation behavior
6. **Data Persistence**: Store all interactions for historical analysis with provider context

## Technology Stack

### Frontend
- **Streamlit** (Python-based web framework)
  - Fast development
  - Great for data visualization
  - Built-in components for expandable sections, JSON display, tables
  - Easy tabbed interfaces

### Backend
- **Python 3.10+**
- **Provider SDKs**:
  - OpenAI Python SDK (Responses API with web_search tool)
  - Google Generative AI SDK (Gemini with search grounding)
  - Anthropic Python SDK (Claude with tool use)
- **SQLAlchemy** (ORM for database operations)
- **Pandas** (for batch analysis and data manipulation)
- **Abstract provider interface** for extensibility

### Database
- **SQLite** (for development/small scale)
- **PostgreSQL** (optional, for production/large scale)

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Streamlit Frontend                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Tab 1: Interactive Prompting               â”‚  â”‚
â”‚  â”‚ Tab 2: Batch Analysis                      â”‚  â”‚
â”‚  â”‚ Tab 3: Query History                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Provider Abstraction Layer                â”‚
â”‚  â€¢ base_provider.py - Abstract interface         â”‚
â”‚  â€¢ provider_factory.py - Provider selection      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Provider Implementations                 â”‚
â”‚  â€¢ openai_provider.py                            â”‚
â”‚  â€¢ google_provider.py                            â”‚
â”‚  â€¢ anthropic_provider.py                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Core Backend                           â”‚
â”‚  â€¢ parser.py - Response parsing                  â”‚
â”‚  â€¢ database.py - Data storage                    â”‚
â”‚  â€¢ analyzer.py - Basic statistics                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Database (SQLite)                   â”‚
â”‚  â€¢ providers                                     â”‚
â”‚  â€¢ sessions                                      â”‚
â”‚  â€¢ prompts                                       â”‚
â”‚  â€¢ responses                                     â”‚
â”‚  â€¢ search_calls                                  â”‚
â”‚  â€¢ sources                                       â”‚
â”‚  â€¢ citations                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features Breakdown

### Tab 1: Interactive Prompting

**Input Section:**
- **Model selector** dropdown with latest models:
  - OpenAI: `gpt-5.1`, `gpt-5-mini`, `gpt-5-nano`
  - Google: `gemini-3-pro-preview`, `gemini-2.5-flash`, `gemini-2.5-flash-lite`
  - Anthropic: `claude-sonnet-4-5-20250929`, `claude-haiku-4-5-20251001`, `claude-opus-4-1-20250805`
- **Prompt** text area
- **Send** button

**Output Display:**
- **Response**: The model's complete response
- **Search Queries**: List of queries the model generated
- **Sources Fetched**: URLs the model consulted (with titles)
- **Citations**: URLs actually cited in the response
- **Summary Stats**:
  - Total searches: X
  - Sources fetched: Y
  - Citations used: Z

### Tab 2: Batch Analysis

**Input:**
- **Prompts** text area (paste multiple prompts, one per line)
- **OR** CSV file upload (with "prompt" column)
- **Model selector** (same as Tab 1)
- **Run** button

**Processing:**
- Progress bar
- Count of completed prompts

**Output:**
- **Summary Stats**:
  - Total prompts: X
  - Total searches: Y
  - Avg sources per prompt: Z
  - Avg citations per prompt: W
- **Top Domains**: Simple bar chart of most common domains
- **Export** button (download results as CSV)

### Tab 3: Query History

**Display:**
- Simple table of past queries
- **Columns**: Timestamp, Prompt (truncated), Model, Searches, Sources, Citations
- **Search** bar to filter by prompt text
- Click a row to view full details
- **Export** button (CSV download)

## Provider API Integration

### OpenAI Integration

**Endpoint:** `/v1/responses`

**Key Configuration:**
```python
from openai import OpenAI
client = OpenAI()

response = client.responses.create(
    model="gpt-5",  # or "o4-mini" for reasoning
    reasoning={"effort": "medium"},  # low/medium/high
    tools=[{
        "type": "web_search",
        "filters": {
            "allowed_domains": ["example.com", "news.site"]  # optional
        },
        "external_web_access": True  # default, can be False for cache-only
    }],
    tool_choice="auto",  # let model decide when to search
    include=["web_search_call.action.sources"],  # CRITICAL: get all sources
    input="Your prompt here"
)
```

### Response Structure to Parse

**Search Call Item:**
```json
{
    "type": "web_search_call",
    "id": "ws_67c9fa0502748190b7dd390736892e100be649c1a5ff9609",
    "status": "completed",
    "action": {
        "type": "search",
        "query": "positive news story today",
        "domains": ["news.com"],
        "sources": [
            {"url": "https://...", "title": "..."},
            ...
        ]
    }
}
```

**Message Item:**
```json
{
    "id": "msg_67c9fa077e288190af08fdffda2e34f20be649c1a5ff9609",
    "type": "message",
    "status": "completed",
    "role": "assistant",
    "content": [
        {
            "type": "output_text",
            "text": "On March 6, 2025, several news...",
            "annotations": [
                {
                    "type": "url_citation",
                    "start_index": 2606,
                    "end_index": 2758,
                    "url": "https://...",
                    "title": "Title..."
                }
            ]
        }
    ]
}
```

### Important API Details

**Three Types of Web Search:**
1. **Non-reasoning web search**: Fast, simple query passthrough
2. **Agentic search with reasoning**: Model manages search process, can iterate
3. **Deep research**: Extended investigations (o3-deep-research, o4-mini-deep-research)

**Action Types:**
- `search` - web search (includes query and domains)
- `open_page` - page opened (reasoning models)
- `find_in_page` - in-page search (reasoning models)

**Key Fields to Extract:**
- `web_search_call.action.query` - the search query
- `web_search_call.action.sources` - ALL URLs fetched (complete list)
- `message.content[0].annotations` - citations actually used (subset of sources)

**Supported Models:**
- `gpt-5` (with reasoning levels: low/medium/high)
- `o4-mini`, `o3-mini` (reasoning models)
- `gpt-5-search-api` (specialized for search)
- NOT supported: `gpt-5` with minimal reasoning, `gpt-4.1-nano`

### Google (Gemini) Integration

**SDK:** `google-generativeai`

**Key Configuration:**
```python
import google.generativeai as genai
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    tools=[genai.Tool.google_search],  # Enable Google Search grounding
)

response = model.generate_content(
    "Your prompt here",
    generation_config={
        "temperature": 0.7,
        "top_p": 0.95,
    }
)
```

**Key Features:**
- **Google Search Grounding**: Uses Google Search to ground responses
- **Automatic source attribution**: Gemini automatically includes grounding metadata
- **Search queries**: Extracted from grounding chunks
- **Citations**: Found in grounding metadata with URLs and snippets

**Key Fields to Extract:**
- `response.candidates[0].grounding_metadata.grounding_chunks` - sources consulted
- `response.candidates[0].grounding_metadata.search_entry_point.rendered_content` - search queries
- `response.candidates[0].grounding_metadata.grounding_supports` - citations with attribution

**Supported Models:**
- `gemini-2.0-flash` (latest with search grounding)
- `gemini-1.5-pro` (extended context with search)
- `gemini-1.5-flash` (fast with search capabilities)

### Anthropic (Claude) Integration

**SDK:** `anthropic`

**Key Configuration:**
```python
from anthropic import Anthropic
client = Anthropic(api_key=os.environ["ANTHROPIC_API_KEY"])

# Define a web search tool
tools = [{
    "name": "web_search",
    "description": "Search the web for current information",
    "input_schema": {
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "Search query"}
        },
        "required": ["query"]
    }
}]

message = client.messages.create(
    model="claude-3.7-sonnet",
    max_tokens=4096,
    tools=tools,
    messages=[{"role": "user", "content": "Your prompt here"}]
)
```

**Key Features:**
- **Tool use capability**: Claude can request tool use via structured outputs
- **Custom tool integration**: Requires external search API (e.g., Brave, Tavily, Perplexity)
- **Extended thinking**: Claude 3.7 Sonnet supports extended thinking mode
- **Citation tracking**: Manual tracking of tool calls and responses

**Key Fields to Extract:**
- `message.content[i].type == "tool_use"` - tool calls (search requests)
- `message.content[i].input.query` - search query
- Tool responses require external API integration
- Citations extracted from final response text

**Supported Models:**
- `claude-3.7-sonnet` (latest with extended thinking)
- `claude-3.5-opus` (most capable)
- `claude-3.5-haiku` (fast and efficient)

**Note:** Anthropic doesn't have native web search, so we'll need to integrate with a search API provider like:
- Brave Search API
- Tavily API
- Perplexity API
- Exa API

## Database Schema

### Tables

**providers**
- id (primary key)
- name (string) - e.g., "openai", "google", "anthropic"
- display_name (string) - e.g., "OpenAI", "Google", "Anthropic"
- api_version (string, nullable)
- is_active (boolean)
- created_at (timestamp)

**sessions**
- id (primary key)
- provider_id (foreign key)
- model_used (string) - e.g., "gpt-5", "gemini-2.0-flash", "claude-3.7-sonnet"
- reasoning_effort (string, nullable)
- created_at (timestamp)

**prompts**
- id (primary key)
- session_id (foreign key)
- prompt_text (text)
- created_at (timestamp)
- response_id (foreign key, nullable)

**responses**
- id (primary key)
- prompt_id (foreign key)
- response_text (text)
- response_time_ms (integer) - for performance comparison
- created_at (timestamp)
- raw_response_json (json)

**search_calls**
- id (primary key)
- response_id (foreign key)
- search_call_id (string) - from API
- action_type (string) - search/open_page/find_in_page
- search_query (text, nullable)
- created_at (timestamp)

**sources**
- id (primary key)
- search_call_id (foreign key)
- url (text)
- title (text, nullable)
- domain (string)
- was_cited (boolean)

**citations**
- id (primary key)
- response_id (foreign key)
- url (text)
- title (text, nullable)
- start_index (integer)
- end_index (integer)
- cited_text (text)

## Project Structure

```
llm-search-analysis/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py                      # Streamlit main app
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_provider.py    # Abstract provider interface
â”‚   â”‚   â”œâ”€â”€ provider_factory.py # Provider selection logic
â”‚   â”‚   â”œâ”€â”€ openai_provider.py  # OpenAI implementation
â”‚   â”‚   â”œâ”€â”€ google_provider.py  # Google/Gemini implementation
â”‚   â”‚   â””â”€â”€ anthropic_provider.py # Anthropic/Claude implementation
â”‚   â”œâ”€â”€ parser.py               # Unified response parsing
â”‚   â”œâ”€â”€ database.py             # SQLAlchemy models & operations
â”‚   â”œâ”€â”€ analyzer.py             # Statistical & comparative analysis
â”‚   â””â”€â”€ config.py               # Configuration management
â”œâ”€â”€ data/
â”‚   â””â”€â”€ llm_search.db           # SQLite database (gitignored)
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ providers/
    â”‚   â”œâ”€â”€ test_openai_provider.py
    â”‚   â”œâ”€â”€ test_google_provider.py
    â”‚   â””â”€â”€ test_anthropic_provider.py
    â”œâ”€â”€ test_parser.py
    â””â”€â”€ test_database.py
```

## Progress Tracker

- âœ… **Phase 1: Core Backend** - COMPLETE
- âœ… **Phase 2: Streamlit UI** - COMPLETE
- â¬œ **Phase 3: Polish & Basic Analytics** - Not Started
- â¬œ **Phase 4: Deploy** - Not Started

## Implementation Steps

### Phase 1: Core Backend âœ… COMPLETE

1. âœ… **Setup project structure**
   - âœ… Initialize git repository
   - âœ… Create virtual environment (user setup)
   - âœ… Create requirements.txt with all provider SDKs
   - âœ… Setup .env.example for multiple API keys

2. âœ… **Build provider abstraction layer**
   - âœ… `base_provider.py`: Abstract base class with standard interface
     - âœ… `send_prompt()` method
     - âœ… `get_supported_models()` method
     - âœ… `get_provider_name()` method
   - âœ… `provider_factory.py`: Factory pattern for provider selection

3. âœ… **Build provider implementations**
   - âœ… `openai_provider.py`: OpenAI Responses API integration
     - âœ… Handle web_search tool
     - âœ… Parse search queries, sources, citations
   - âœ… `google_provider.py`: Google Gemini integration
     - âœ… Handle Google Search grounding
     - âœ… Extract grounding metadata
     - âœ… Resolve redirect URLs to actual destinations
   - âœ… `anthropic_provider.py`: Anthropic Claude integration
     - âœ… Full implementation with web_search_20250305 tool
     - âœ… Parse search queries from server_tool_use blocks
     - âœ… Parse sources from web_search_tool_result blocks
     - âœ… Extract citations from text block annotations
     - âœ… Link queries with their corresponding results

4. âœ… **Build unified parser module** (`src/parser.py`)
   - âœ… Helper utilities for parsing
   - âœ… Domain extraction
   - âœ… Text formatting

5. âœ… **Build database module** (`src/database.py`)
   - âœ… Define SQLAlchemy models with provider support
   - âœ… CRUD operations for all tables including providers table
   - âœ… Helper functions for saving interactions
   - âœ… Query functions for recent interactions

6. âœ… **Build analyzer module** (`src/analyzer.py`)
   - âœ… Batch statistics calculations
   - âœ… Domain frequency analysis
   - âœ… CSV export formatting

7. âœ… **Build config module** (`src/config.py`)
   - âœ… Environment variable management
   - âœ… API key configuration

8. âœ… **Testing**
   - âœ… Write tests for each provider
   - âœ… Test with mocked API responses
   - âœ… Database and analyzer tests
   - âœ… Provider factory tests
   - âœ… Integration testing with real APIs (verify_providers.py)
   - âœ… All 9 models verified working

### Phase 2: Streamlit UI âœ… COMPLETE

**Status:** Full 3-tab interface complete with database integration and all 9 models working.

**Session 1 Accomplishments:**
- âœ… Sources grouped by search query with collapsible sections
- âœ… Fixed text area error and model name truncation
- âœ… Provider and model name formatting improvements
- âœ… Google redirect URL resolution to actual destinations
- âœ… Citation accuracy fixes and documentation
- âœ… Terminology change: "Citations Used" â†’ "Sources Used"
- âœ… Human-friendly model names throughout UI
- âœ… Comprehensive help documentation for source behavior nuances

**Session 2 Accomplishments:**
- âœ… Complete database integration with SQLite
- âœ… Three-tab interface implementation
- âœ… Batch analysis with CSV upload and progress tracking
- âœ… Query history with search and detail views
- âœ… Auto-save all interactions to database

9. âœ… **Main app setup** (`app.py`)
   - âœ… Initialize Streamlit app
   - âœ… Setup page configuration and styling
   - âœ… Three-tab layout (Interactive, Batch Analysis, History)
   - âœ… Database initialization on startup

10. âœ… **Tab 1: Interactive Prompting**
    - âœ… Model selector dropdown with all 9 models across 3 providers
    - âœ… Provider-specific emojis and formatting (ðŸŸ¢ OpenAI, ðŸ”µ Google, ðŸŸ£ Anthropic)
    - âœ… Human-friendly model names (e.g., "Claude Sonnet 4.5", "GPT-5.1")
    - âœ… Prompt input text area
    - âœ… Send button with formatted loading state showing model name
    - âœ… Display response metadata (provider, model, response time, query counts)
    - âœ… Display response text with markdown formatting
    - âœ… Display search queries grouped with their sources
    - âœ… Collapsible source sections per query
    - âœ… Display sources used (citations) in dedicated section
    - âœ… Source details: title, domain, clickable URLs
    - âœ… Google redirect URL resolution to actual destinations
    - âœ… Citation accuracy (Google limitations documented)
    - âœ… Help documentation explaining source behavior nuances
    - âœ… Custom CSS styling for better visual hierarchy
    - âœ… Error handling and user-friendly error messages
    - âœ… Auto-save interactions to database

11. âœ… **Tab 2: Batch Analysis**
    - âœ… Multi-line text area for prompts (one per line)
    - âœ… CSV file upload option with 'prompt' column
    - âœ… Model selection for batch processing
    - âœ… Progress bar tracking with status messages
    - âœ… Summary statistics (total, successful, avg sources/citations)
    - âœ… Detailed results table with all metrics
    - âœ… CSV export with timestamps
    - âœ… Error handling and failed prompt reporting
    - âœ… Auto-save all batch interactions to database

12. âœ… **Tab 3: Query History**
    - âœ… Table display of recent 100 interactions
    - âœ… Search/filter by prompt keywords
    - âœ… Sortable columns (timestamp, prompt, provider, model, stats)
    - âœ… CSV export functionality
    - âœ… Interactive detail view selector
    - âœ… Full interaction details (prompt, response, queries, citations)
    - âœ… Direct database integration for retrieval

### Phase 3: Polish & Basic Analytics â¬œ NOT STARTED

13. â¬œ **Enhanced visualizations**
    - â¬œ Improve domain bar chart styling
    - â¬œ Add tooltips and interactivity
    - â¬œ Clean table displays

14. â¬œ **Error handling**
    - â¬œ User-friendly error messages
    - â¬œ API key validation
    - â¬œ Rate limiting handling

### Phase 4: Deploy â¬œ NOT STARTED

15. â¬œ **Final polish**
    - â¬œ Loading states and feedback
    - â¬œ UI/UX improvements
    - â¬œ Documentation updates

16. â¬œ **Deployment**
    - â¬œ Test locally: `streamlit run app.py`
    - â¬œ Optional: Deploy to Streamlit Cloud

## Dependencies (requirements.txt)

```
# Web Framework
streamlit>=1.30.0

# AI Provider SDKs
openai>=1.12.0
google-generativeai>=0.3.0
anthropic>=0.18.0

# Database & Data
sqlalchemy>=2.0.25
pandas>=2.1.4

# Utilities
python-dotenv>=1.0.0

# Visualization
plotly>=5.18.0

# Testing
pytest>=7.4.3
```

## Environment Variables (.env)

```
# AI Provider API Keys
OPENAI_API_KEY=your_openai_key_here
GOOGLE_API_KEY=your_google_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here

# Database
DATABASE_URL=sqlite:///data/llm_search.db
```

## Key Considerations

### API Costs
- Be aware each provider charges differently
- For MVP: just track basic usage (can add cost tracking later)

### Rate Limits
- Handle rate limit errors with simple retry logic
- Show user-friendly error messages

### Data Privacy
- Store API responses locally
- Don't commit .env file or database to git
- Consider encryption for sensitive prompts

### Performance
- Basic database operations (SQLite is fine for MVP)
- Simple error handling

### Provider-Specific Considerations
- **OpenAI**: Native web_search support
- **Google**: Built-in grounding
- **Anthropic**: Requires external search API (defer to future version)

## Success Metrics (MVP)

The beta app should help you understand:

1. What search queries does each model generate?
2. How many sources do they fetch vs. cite?
3. Which domains appear most frequently?
4. Basic comparison between the three models

## Next Steps

1. Set up project structure and virtual environment
2. Install dependencies
3. Implement Phase 1 (Core Backend with provider abstraction)
4. Start with OpenAI and Google providers (native search support)
5. Build basic Streamlit UI (3 tabs)
6. Test and iterate

## Future Enhancements / Backlog

Features deferred from MVP for future versions:

### Tab Enhancements
- **Tab 1**:
  - Reasoning effort slider (for models that support it)
  - Domain filtering (allow/block specific domains)
  - Detailed reasoning traces display
  - Raw API response viewer
  - Character-level citation tracking
- **Tab 2**:
  - Word cloud visualizations
  - Complex citation ratio analysis
  - Estimated time remaining
  - Per-provider batch statistics
- **Tab 3**:
  - Advanced filters (date range, multiple models)
  - Statistical dashboard with time-series charts
  - Search pattern analysis
  - Average reasoning time tracking

### New Features
- **Tab 4: Cross-Provider Comparison**
  - Side-by-side model comparison
  - Multi-model prompt testing
  - Source overlap analysis (Venn diagrams)
  - Radar charts for metric comparison
  - Cost comparison across providers
  - Response time benchmarking

### Provider Support
- **Anthropic/Claude full integration**
  - External search API integration (Brave, Tavily, Perplexity, Exa)
  - Manual citation tracking
  - Tool use monitoring

### Analytics & Insights
- Advanced visualizations:
  - Word clouds for search terms
  - Domain network graphs
  - Search pattern clustering
  - Heat maps for usage patterns
- Cost tracking and analysis
- Provider performance monitoring
- Citation quality metrics
- Time-series trend analysis

### Infrastructure
- PostgreSQL support for production
- Caching layer for performance
- Async operations for concurrent requests
- Provider health monitoring and fallbacks
- Request queuing and rate limiting per provider
- Provider enable/disable toggles
- Docker containerization
- Cloud deployment automation

### Polish
- Export options (JSON in addition to CSV)
- Shareable query links
- User authentication (multi-user support)
- Custom prompt templates
- Saved search configurations
- Dark mode UI theme

## Additional Resources

**Provider APIs:**
- [OpenAI API Docs](https://platform.openai.com/docs)
- [Google Gemini API Docs](https://ai.google.dev/docs)
- [Anthropic API Docs](https://docs.anthropic.com/)

**Frameworks:**
- [Streamlit Documentation](https://docs.streamlit.io/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
