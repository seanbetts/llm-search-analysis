Codebase Audit Instructions for Agent

(Version 1.0 â€” for FastAPI + SQLite + Python + Streamlit project)

â¸»

ğŸ¯ Objective

Perform a one-off, full codebase audit and produce a structured markdown report of the systemâ€™s architecture, risks, quality gaps and improvement recommendations.

The agent must both analyse the repository and write the audit output into:

docs/reviews/CODEBASE_AUDIT.md

(Create directories if they do not exist.)

â¸»

ğŸ” Preparation Step â€” Generate Repository View

Before analysing, the agent must generate a high-level file tree using:

tree -L 3 -I '__pycache__|.git|venv|.mypy_cache|.pytest_cache|node_modules|*.pyc|*.db'

Insert this tree output near the top of the audit report for reference.

â¸»

ğŸ§­ What to Read & Consider

The agent should review:
	â€¢	README.md
	â€¢	docs/backend/OVERVIEW.md
	â€¢	docs/frontend/OVERVIEW.md
	â€¢	docs/operations/ENVIRONMENT_VARIABLES.md
	â€¢	Any API docs or testing docs found in docs

Use file names and test suites to infer intended behaviour.

â¸»

ğŸ“Œ Audit Report Output Structure

The markdown report must follow this outline:

â¸»

Codebase Audit Report

1. Architecture & Data Flow Summary

5â€“8 sentences describing:
	â€¢	FastAPI backend flow
	â€¢	Repository/service layering
	â€¢	SQLite storage model
	â€¢	Provider integrations
	â€¢	Frontendâ†’backend interaction model

â¸»

2. Repository Snapshot

(Insert tree -L 3 ... output here)

â¸»

3. Top 10 Findings

Ranked issues or improvement opportunities, each with a one-sentence remediation.

â¸»

4. Section Reviews

4.1 Backend (FastAPI)
	â€¢	Strengths
	â€¢	Weaknesses / risks
	â€¢	Suggested improvements

4.2 SQLite Database & Migrations
	â€¢	Observed schema
	â€¢	Migration gaps or drift
	â€¢	Query / indexing risk
	â€¢	Suggested improvements

4.3 Provider Integrations

(Anthropic, OpenAI, Google, factories and validation)
	â€¢	Strengths
	â€¢	Weaknesses
	â€¢	Suggested improvements

4.4 Frontend (Streamlit & frontend package)
	â€¢	UX / structure findings
	â€¢	Code organisation risks
	â€¢	Suggested improvements

4.5 Testing & Quality
	â€¢	Coverage strength
	â€¢	Blind spots
	â€¢	5 specific tests to add next

4.6 Tooling, Docker & Operational Model
	â€¢	Observations on scripts, compose usage, run lifecycle
	â€¢	Risks
	â€¢	Suggested improvements

â¸»

5. Suggested Improvement Roadmap

Break into three phases:

Phase 1 â€” Quick Wins (under 1 day)

(3â€“6 items)

Phase 2 â€” Structural Improvements

(3â€“6 items)

Phase 3 â€” Nice-to-Haves

(3â€“6 items)

â¸»

6. Appendix

(Optional endpoint table, schema notes, diagrams)

â¸»

â¸»

ğŸ—ï¸ How the Agent Should Perform the Audit

Step 1 â€” Build mental model

Scan docs + file layout, identify pipelines, service layers and data flow.

Step 2 â€” Backend review

Walk backend/app/api, services, repositories, models, core, dependencies.

Step 3 â€” Database & repositories

Inspect Alembic migrations and live DB file structure, assess repository patterns.

Step 4 â€” Provider abstraction audit

Trace provider tests to implementation; inspect validation and error handling.

Step 5 â€” Frontend review

Inspect app.py Streamlit entrypoint + frontend/ components, config, helpers, network capture and tabs.

Step 6 â€” Tests & coverage

Inventory coverage and identify missing validation paths.

Step 7 â€” Tooling & operational scan

Analyse Dockerfiles, scripts, config docs vs reality.

Step 8 â€” Generate markdown

Write findings using the required structure.

Step 9 â€” Save output file

Write the result as:

docs/reviews/CODEBASE_AUDIT.md

Return this path as final confirmation.

â¸»

ğŸ“Œ Output Rules
	â€¢	Be concise, concrete and reference real file paths where applicable.
	â€¢	Use bullet points, headings and tables where helpful.
	â€¢	Do not output raw commentary in chat â€” write to the markdown file.
	â€¢	Final message should contain only:
docs/reviews/CODEBASE_AUDIT.md